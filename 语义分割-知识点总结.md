[TOC]

# 语义分割-知识点总结
目的：汇总一些在语义分割中的知识点，并增加自己的理解

## 1. Depthwise separable convolution

### 参考文献：  
[1]	 [深度學習-MobileNet (Depthwise separable convolution)](https://medium.com/@chih.sheng.huang821/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-mobilenet-depthwise-separable-convolution-f1ed016b3467)

### 正文
1.	MobileNet，由Google在2017年提出。主要是为了减少模型的参数量和计算量，同时保持模型的性能。
2.	在参数众多的网络模型中，计算量最多的运算发生在卷积运算中（全连接和卷积不同，它比卷积的运算量更大，可以使用SVD分解拆分全连接层减少计算量）。这里把卷积运算拆分成了两部分:
	+ Depthwise convolution：针对输入资料的每一个Channel都建立一个k*k的Kernel，然后每一个Channel针对对应的Kernel都各自(分开)做convolution。这步骤和一般卷积不太一样，一般的卷积计算是每个Kernel Map都要和所有channel都去做convolution，这边是分开独立去做。各个卷积核只负责一个对应的通道，不会去和别的通道发生卷积行为。
	+ Pointwise convolution：在输入资料的每个channel做完depthwise convolution后，针对每个点，跨越所有channel做pointwise convolution。实际做法是建立Nk个1\*1\*Nch的kernel Map，将depthwise convolution的输出做一般1*1的卷积计算

### 第一步的示意图：
![](https://github.com/zhixuanli/segmentation-paper-reading-notes/blob/master/images-folder/Depthwise-separable-convolution-1.jpg)

### 第二步的示意图：
![](https://github.com/zhixuanli/segmentation-paper-reading-notes/blob/master/images-folder/Depthwise-separable-convolution-2.jpg)

## 2. atrous convolution 带洞卷积

### 参考文献：  
[1]	[https://www.zhihu.com/question/49630217](https://www.zhihu.com/question/49630217)

### 示意图：  
![](https://github.com/zhixuanli/segmentation-paper-reading-notes/blob/master/images-folder/atrous-convolution-1.jpg)

+ （a）是正常的卷积，最下面是输入特征，最上面是输出特征，中间是卷积。卷积就是那三条线。
+ （b）是带洞卷积，中间三条红色的线就是卷积核大小为3时的卷积过程，可以看到是从5个点找了依次相隔一个的点，也就是3个点来进行卷积。相邻点之间的距离dis为1，这里的rate=2表示要有两个dis，说明有三个相邻点，才能有两个dis。 
如果rate = 3，卷积核仍为3，则应该每次间隔2个点进行卷积

### 总结：  
1. 是输入的值“空洞”了，而非卷积核“空洞”了。空洞指的是跳过固定多的值
2. rate=n，则应该每间隔n-1个点进行一次卷积
3.	Note that standard convolution is a special case in which rate r = 1

## 3. Spatial pyramid pooling

### 参考文献：  
+ [1]	[https://www.jianshu.com/p/e36aef9b7a8a](https://www.jianshu.com/p/e36aef9b7a8a)  
+ [2]	[https://www.jianshu.com/p/884c2828cd8e](https://www.jianshu.com/p/884c2828cd8e)  
+ [3]	[http://www.cnblogs.com/marsggbo/p/8572846.html#commentform](http://www.cnblogs.com/marsggbo/p/8572846.html#commentform)  
+ [4]	[https://github.com/yueruchen/sppnet-pytorch/blob/master/spp_layer.py](https://github.com/yueruchen/sppnet-pytorch/blob/master/spp_layer.py)


**论文地址**：[Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition](https://arxiv.org/abs/1406.4729)

SPP提出的初衷是为了解决CNN对输入图片尺寸的限制。由于全连接层的存在，与之相连的最后一个卷积层的输出特征需要固定尺寸，从而要求输入图片尺寸也要固定

### 解决方案：
+ 方案1：对输入进行resize，统一到同一大小。
+ 方案2：取消全连接层，对最后的卷积层global average polling（GAP。
+ 方案3：在第一个全连接层前，加入SPP layer。本文要介绍的。

方案1，即spp-net之前的做法是将图片裁剪或变形（crop/warp），如下图所示

![](https://github.com/zhixuanli/segmentation-paper-reading-notes/blob/master/images-folder/Spatial-pyramid-pooling-1.jpg)

但是crop/warp的一个问题是导致图片的信息缺失或变形，影响识别精度。对此，文章中在最后一层卷积特征图的基础上又进一步进行处理，提出了spatial pyramid pooling，即方案3，如图所示：

![](https://github.com/zhixuanli/segmentation-paper-reading-notes/blob/master/images-folder/Spatial-pyramid-pooling-2.jpg)

以VGG16网络为例，如下图

![](https://github.com/zhixuanli/segmentation-paper-reading-notes/blob/master/images-folder/Spatial-pyramid-pooling-3.jpg)

现有两种规格输入：224\*224\*3和180\*180\*3  
准备在全连接层前加入spp net，也就是上图7\*7\*512那一层后。  

+ 224\*224\*3：全连接层前卷积层大小7\*7\*512
+ 180\*224\*3：全连接层前卷积层大小5\*5\*517  

由于这样不同大小卷积层全连接到1\*1\*4096，权值W是不一样的，所以要统一全连接的输入大小

### SPP layer方法：
用不同size，stride的pooling layer，对全连接层前的卷积层进行pooling，然后做flatten。见下图

![](https://github.com/zhixuanli/segmentation-paper-reading-notes/blob/master/images-folder/Spatial-pyramid-pooling-4.jpg)

对于一个三层的金字塔（也可以设置为多层的金字塔，如作者在detection问题中使用过a 4-level spatial pyramid (1x1, 2x2, 3x3, 6x6, totally 50 bins)），将任意尺寸的feature map分别切分成16、4、1份（这里16、4、1即为各个层bin的数量），再对每一份进行池化操作（一般选择max pooling），将池化后的结果拼接得到固定长度的特征向量（图中的256为filter的个数），送入全连接层进行后续操作。

原文给出的计算公式如下[3]：

![](Spatial-pyramid-pooling-5.jpg)

#### 按照[1]中的例子进行计算：  
输入512\*7\*7时：bin大小分别为4\*4, 2\*2, 1\*1。  
对于第一个pooling layer(bin_size = 4*4): 此时  

+ kernel_size = ceil(7 / 4, 7 / 4) = (2, 2)
+ stride = floor(7 / 4, 7 / 4) = (1, 1)   

按照Output = (W-Kernel+2P)/S+1 （其中P是padding）的计算公式，这里令Padding = 0，则Output = （7 - 2 + 2*0）/1 + 1 = 6， 即pooling后的输出feature大小为6 x 6。

**而目标输出应该是4 x 4，即bin的大小。**

这里是公式上出现了问题，原文给的公式有两个问题： 

1. 没有给出padding的计算方法（虽然很多文章都没有给，但是在这里padding是比较重要的）
2.	stride应该是向上取整（ceil）而非向下取整


按照原文的公式来计算，即使是不加padding，也会因为stride太小而导致输出的特征图太大。

#### 基于以上两点原因，结合[4]中的代码实现，公式应该更正为（h和w计算方法相同）
 ![](https://github.com/zhixuanli/segmentation-paper-reading-notes/blob/master/images-folder/Spatial-pyramid-pooling-6.jpg)

output_size = floor((H-K+2*P)/S+1) (H为输入特征高度)

假设h=w，图片的长和宽是相等的，则

+ 上图中K表示kernel_size，即下面的size，也就是pooling的滑动窗口大小。
+ S表示stride。
+ p表示padding。
+ h_new和w_new表示加上padding后的高和宽
+ n表示bin的大小。bin在这里指的是要输出的格子数量。比如下面的公式的bin分别为4x4, 2x2, 1x1

#### 按照修正后的公式举例：
**输入7\*7\*512时：**  
pooling layer1(输出4\*4\*512): 

+ kernel_size = 7/4(向上取整)=2, 
+ stride = 7/4(向上取整)=2, 
+ padding = floor((2*4-7+1)/2) = 1, 
+ output = floor[(7-2+2*1)/2+1] = floor(4.5) = 4

pooling layer2(输出2\*2\*512): 

+ kernel_size = 7/2(向上取整)=4, 
+ stride = 7/2(向上取整)=4, 
+ padding = f((4*2-7+1)/2)=1, 
+ output = f[(7-4+2*1)/4+1] = f(2.5) = 2

pooling layer3(输出1\*1\*512):  
+ kernel_size = 7/1(向上取整)=7, 
+ stride = 7/1(向上取整)=7, 
+ padding = f((7*1-7+1)/2)=0, 
+ output = f[(7-7+0)/7+1] = 1 

然后做flatten，输出（4\*4+2\*2+1）\*512 = 21\*512，即把一个有512个通道的21维向量送到接下来的全连接层


**输入5\*5\*512时：**  
pooling layer1(输出4\*4\*512): 

+ kernel_size = 5/4(向上取整)=2, 
+ stride = 5/4(向上取整)=2, 
+ padding = f((2*4-5+1)/2) = f(2) = 2, 
+ output = f[(5-2+2*2)/2+1] = f(4.5) = 4 


pooling layer2(输出2\*2\*512): 

+ kernel_size = 5/2(向上取整)=3, 
+ stride = 5/2(向上取整)=3, 
+ padding = f((3*2-5+1)/2) = f(1) = 1, 
+ output = f[(5-3+2*1)/3+1] = f(7/3) = 2 

pooling layer3(输出1\*1\*512):  

+ kernel_size = 5/1(向上取整)=5, 
+ stride = 5/1(向上取整)=5, 
+ padding = f((5*1-5+1)/2) = f(0.5) = 0, 
+ output = f[(5-5+0)/5+1] = f(1) = 1 

然后做flatten，输出（4\*4+2\*2+1）\*512=21\*512

这样全连接层输入都是21*512，是跟网络输入图像size大小无关的。

### 总结：为什么SPP有优势  
1.	传统的Pooling无法统一尺寸，这里对不同尺寸的feature给不同的size和stride的pooling。其实在这一步已经解决了输入fc层尺寸不统一的问题。
2.	为了减少pooling层对信息的损失，尽可能的保留更丰富的特征信息，要经过多个尺寸的pooling layer，并把三者的结果连接在一起以使得FC层的输入信息更加丰富。即 

